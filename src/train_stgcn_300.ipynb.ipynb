{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13167700,"sourceType":"datasetVersion","datasetId":8343837},{"sourceId":13169935,"sourceType":"datasetVersion","datasetId":8345437}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as Data\nimport numpy as np\nimport random\nimport math\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom torch.cuda.amp import GradScaler, autocast\nimport os, math, json, random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom sklearn.utils.class_weight import compute_class_weight\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T06:37:43.322372Z","iopub.execute_input":"2025-09-26T06:37:43.322647Z","iopub.status.idle":"2025-09-26T06:37:43.327786Z","shell.execute_reply.started":"2025-09-26T06:37:43.322628Z","shell.execute_reply":"2025-09-26T06:37:43.327081Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"\n\nLANDMARK_FILE = '/kaggle/input/bones-joints/Landmarks_GCN_augmented.npz'\nSPLIT_FILE = '/kaggle/input/json-file/nslt_300.json'\nNUM_CLASSES = 300\nTOTAL_LANDMARKS = 67  # 15 pose + 2 mid + 42 hands + 8 face = 67\nC = 4                # x,y,z\nT_FRAMES = 128          # fixed temporal length to sample to\nBATCH_SIZE = 32\nEPOCHS = 350\nBASE_LR = 3e-4\nWEIGHT_DECAY = 1e-4\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nUSE_AMP = True\nMIXUP_ALPHA = 0.4\nLABEL_SMOOTHING = 0.1\ndef temporal_resample(sequence, target_len):\n    \"\"\"Resample sequence (T, V, C) to (target_len, V, C) using linear interpolation per coordinate.\"\"\"\n    orig_len = sequence.shape[0]\n    if orig_len == target_len:\n        return sequence\n    if orig_len == 1:\n        return np.repeat(sequence, target_len, axis=0)\n    # compute target indices in original timeline\n    target_positions = np.linspace(0, orig_len - 1, target_len)\n    old_idx = np.arange(orig_len)\n    out = np.zeros((target_len, sequence.shape[1], sequence.shape[2]), dtype=sequence.dtype)\n    for v in range(sequence.shape[1]):\n        for c in range(sequence.shape[2]):\n            values = sequence[:, v, c]\n            out[:, v, c] = np.interp(target_positions, old_idx, values)\n    return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T06:38:50.325362Z","iopub.execute_input":"2025-09-26T06:38:50.325646Z","iopub.status.idle":"2025-09-26T06:38:50.332331Z","shell.execute_reply.started":"2025-09-26T06:38:50.325618Z","shell.execute_reply":"2025-09-26T06:38:50.331574Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"\nclass LandmarkPreprocessor:\n    def __init__(self, augment=True, target_frames=T_FRAMES):\n        self.augment = augment\n        self.target_frames = target_frames\n        \n        # New indices for 67 landmarks\n        # Pose 15, mid 2, hands 42, face 8\n        self.POSE_IDXS = list(range(0, 17))  # 15 pose + 2 mid\n        self.LEFT_HAND_IDXS = list(range(17, 38))\n        self.RIGHT_HAND_IDXS = list(range(38, 59))\n        self.FACE_IDXS = list(range(59, 67))\n\n    def normalize_frame(self, frame):\n        \"\"\"\n        frame: (V, 3) with x,y in [0,1] relative image, z relative depth\n        \"\"\"\n        normalized = frame.copy()\n        \n        # Pose and Face Normalization\n        pose = frame[self.POSE_IDXS, :2]\n        if np.sum(np.abs(pose)) > 0:\n            try:\n                nose = pose[0]\n                l_s = pose[1]  # Assumes left shoulder is at index 1\n                r_s = pose[2]  # Assumes right shoulder is at index 2\n                \n                if np.all(l_s == 0) or np.all(r_s == 0):\n                    l_s = np.nan_to_num(np.mean(pose, axis=0))\n                    r_s = l_s + 0.1\n                dist = np.linalg.norm(l_s - r_s)\n            except Exception:\n                dist = 0.1\n                nose = np.nan_to_num(np.mean(pose, axis=0))\n            \n            if dist < 1e-4: dist = 0.1\n            hu = dist / 2.0\n            bw = 6 * hu\n            bh = 7 * hu\n            bx = nose[0] - 3 * hu\n            by = nose[1] - 0.5 * hu\n            \n            pf_idxs = self.POSE_IDXS + self.FACE_IDXS\n            if bw > 0 and bh > 0:\n                normalized[pf_idxs, 0] = (frame[pf_idxs, 0] - bx) / bw - 0.5\n                normalized[pf_idxs, 1] = (frame[pf_idxs, 1] - by) / bh - 0.5\n\n        # Hand Normalization\n        for h_idxs in [self.LEFT_HAND_IDXS, self.RIGHT_HAND_IDXS]:\n            hand = frame[h_idxs]\n            if np.sum(np.abs(hand)) > 0:\n                xs = hand[:, 0]; ys = hand[:, 1]\n                if np.max(xs) != np.min(xs) or np.max(ys) != np.min(ys):\n                    xmin, xmax, ymin, ymax = np.min(xs), np.max(xs), np.min(ys), np.max(ys)\n                    box_size = max(xmax - xmin, ymax - ymin, 1e-4)\n                    normalized[h_idxs, 0] = (hand[:, 0] - xmin) / box_size - 0.5\n                    normalized[h_idxs, 1] = (hand[:, 1] - ymin) / box_size - 0.5\n\n        # Z-axis Normalization\n        try:\n            torso_z = frame[self.POSE_IDXS, 2]\n            torso_z_nonzero = torso_z[torso_z != 0]\n            if len(torso_z_nonzero) > 0:\n                median_z = np.median(torso_z_nonzero)\n                normalized[:, 2] = (frame[:, 2] - median_z)\n        except Exception:\n            pass\n        \n        return normalized\n\n    def augment_sequence(self, seq):\n        # rotation noise\n        angle = random.uniform(-12, 12)\n        rad = math.radians(angle)\n        cos, sin = math.cos(rad), math.sin(rad)\n        R = np.array([[cos, -sin], [sin, cos]], dtype=np.float32)\n        xy = seq[:, :, :2].reshape(-1, 2)\n        xy = xy @ R.T\n        seq[:, :, :2] = xy.reshape(seq.shape[0], seq.shape[1], 2)\n        seq += np.random.normal(0, 0.003, size=seq.shape).astype(np.float32)\n    \n        # ðŸ”¹ temporal jitter: randomly drop or duplicate frames\n        if random.random() < 0.5:\n            T = seq.shape[0]\n            jittered = []\n            for t in range(T):\n                if random.random() < 0.05 and t < T-1:  # drop chance\n                    continue\n                jittered.append(seq[t])\n                if random.random() < 0.05:  # duplicate chance\n                    jittered.append(seq[t])\n            if len(jittered) < 2:\n                jittered = [seq[t] for t in range(T)]\n            jittered = np.stack(jittered, axis=0)\n            seq = temporal_resample(jittered, self.target_frames)  # resample back\n    \n        return seq\n\n\n    def __call__(self, landmark_sequence: np.ndarray, is_train: bool):\n        landmark_sequence = np.nan_to_num(landmark_sequence, 0.0).astype(np.float32)\n        seq = temporal_resample(landmark_sequence, self.target_frames)\n        seq = np.stack([self.normalize_frame(frame) for frame in seq], axis=0)\n        if is_train and self.augment:\n            seq = self.augment_sequence(seq)\n        return seq\nclass WLASLLandmarkDataset(Dataset):\n    def __init__(self, landmark_path, split_file_path, split='train', preprocessor=None):\n        self.split = split\n        self.preprocessor = preprocessor if preprocessor is not None else LandmarkPreprocessor()\n        landmarks_data = dict(np.load(landmark_path, allow_pickle=True))\n        with open(split_file_path, 'r') as f:\n            split_data = json.load(f)\n        split_dict = split_data.get('root', split_data)\n        self.samples = []\n        # Build mapping from gloss -> class idx consistent with training classes\n        # We'll assume nslt_* uses 'gloss' keys; but here info contains 'subset' and 'action' in their json.\n        for video_id, info in split_dict.items():\n            subset = info.get('subset') or info.get('split') or info.get('subset', None)\n            if subset == self.split:\n                if video_id in landmarks_data:\n                    # extract label safely\n                    action = info.get('action', [])\n                    if not isinstance(action, list) or len(action) == 0:\n                        continue\n                    try:\n                        label = int(action[0])\n                    except Exception:\n                        # fallback - try gloss index mapping (if present)\n                        continue\n                    self.samples.append({\"video_id\": video_id, \"landmarks\": landmarks_data[video_id], \"label\": label})\n        print(f\"âœ… Created '{self.split}' split with {len(self.samples)} samples.\")\n\n    def __len__(self): return len(self.samples)\n\n    def __getitem__(self, idx):\n        sample = self.samples[idx]\n        landmark_sequence = sample[\"landmarks\"]  # expected (T_orig, V, 3)\n        # if saved arrays are (T, V, 3) or (T, V*3) handle both\n        if landmark_sequence.ndim == 2 and landmark_sequence.shape[1] == TOTAL_LANDMARKS * 3:\n            landmark_sequence = landmark_sequence.reshape(-1, TOTAL_LANDMARKS, 3)\n        # preprocess (resample + normalize + augment)\n        processed = self.preprocessor(landmark_sequence, is_train=(self.split == 'train'))  # (T_FRAMES, V, 3)\n        # transpose to (C, T, V)\n        processed = np.transpose(processed, (2, 0, 1)).astype(np.float32)\n        label = int(sample['label'])\n        return torch.from_numpy(processed), torch.tensor(label, dtype=torch.long)\n\ndef collate_fn(batch):\n    # batch of (tensor(C,T,V), label)\n    xs, ys = zip(*batch)\n    xs = torch.stack(xs, dim=0)  # (B, C, T, V)\n    ys = torch.tensor(ys, dtype=torch.long)\n    return xs, ys\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T06:38:51.492627Z","iopub.execute_input":"2025-09-26T06:38:51.493155Z","iopub.status.idle":"2025-09-26T06:38:51.513319Z","shell.execute_reply.started":"2025-09-26T06:38:51.493129Z","shell.execute_reply":"2025-09-26T06:38:51.512581Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"\nclass GraphConv(nn.Module):\n    def __init__(self, in_channels, out_channels, num_nodes, bias=True):\n        super().__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        # weight for transform: (in_channels, out_channels)\n        self.theta = nn.Parameter(torch.Tensor(in_channels, out_channels))\n        # learnable adjacency (initialized as identity)\n        self.A = nn.Parameter(torch.eye(num_nodes, dtype=torch.float32), requires_grad=True)\n        if bias:\n            self.bias = nn.Parameter(torch.zeros(out_channels))\n        else:\n            self.register_parameter('bias', None)\n        nn.init.xavier_uniform_(self.theta)\n\n    def forward(self, x):\n        # x: (B, C_in, T, V)\n        B, C, T, V = x.shape\n        # reshape to (B*T, V, C)\n        x_perm = x.permute(0, 2, 3, 1).contiguous().view(B * T, V, C)  # (B*T, V, C)\n        # multiply by theta: result (B*T, V, out_channels)\n        y = x_perm @ self.theta  # (B*T, V, out_channels)\n        # aggregate neighbors with adjacency A: (V,V) dot (B*T,V,out) -> (B*T,V,out)\n        A = self.A.unsqueeze(0)  # (1, V, V)\n        y = torch.bmm(A.repeat(B * T, 1, 1), y)  # (B*T, V, out)\n        y = y.view(B, T, V, self.out_channels).permute(0, 3, 1, 2).contiguous()  # (B, out, T, V)\n        if self.bias is not None:\n            y = y + self.bias.view(1, -1, 1, 1)\n        return y\n\nclass STGCNBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, num_nodes, kernel_size=9, stride=1, residual=True):\n        super().__init__()\n        self.gcn = GraphConv(in_channels, out_channels, num_nodes)\n        padding = (kernel_size - 1) // 2\n        self.tcn = nn.Sequential(\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=(kernel_size, 1), padding=(padding, 0), stride=(stride, 1)),\n            nn.BatchNorm2d(out_channels),\n            nn.Dropout(0.3)\n        )\n        if not residual:\n            self.residual = lambda x: 0\n        elif (in_channels == out_channels) and stride == 1:\n            self.residual = lambda x: x\n        else:\n            self.residual = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=(stride,1)),\n                nn.BatchNorm2d(out_channels),\n            )\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        # x: (B, C, T, V)\n        res = self.residual(x)\n        x = self.gcn(x)  # (B, out, T, V)\n        x = self.tcn(x)\n        x = x + res\n        return self.relu(x)\n\nclass TemporalSelfAttention(nn.Module):\n    def __init__(self, d_model, n_heads=4):\n        super().__init__()\n        self.attn = nn.MultiheadAttention(d_model, n_heads, batch_first=True)\n        self.ln = nn.LayerNorm(d_model)\n\n    def forward(self, x):\n        # x: (B, C, T, V)\n        B, C, T, V = x.shape\n        # treat joints independently â†’ (B*V, T, C)\n        x = x.permute(0, 3, 2, 1).contiguous().view(B * V, T, C)\n        out, _ = self.attn(x, x, x)\n        out = self.ln(out + x)  # residual + LN\n        # reshape back to (B, C, T, V)\n        out = out.view(B, V, T, C).permute(0, 3, 2, 1).contiguous()\n        return out\n\n\nclass STGCN(nn.Module):\n    def __init__(self, in_channels, num_class, num_nodes, edge_importance_weighting=True):\n        super().__init__()\n        self.data_bn = nn.BatchNorm1d(in_channels * num_nodes)\n        # build layers\n        self.layers = nn.ModuleList([\n            STGCNBlock(in_channels, 64, num_nodes, kernel_size=9, stride=1, residual=False),\n            STGCNBlock(64, 64, num_nodes, kernel_size=9, stride=1),\n            STGCNBlock(64, 128, num_nodes, kernel_size=9, stride=2),\n            STGCNBlock(128, 256, num_nodes, kernel_size=9, stride=2),\n        ])\n        self.temporal_attn = TemporalSelfAttention(d_model=256, n_heads=4)\n\n        self.pool = nn.AdaptiveAvgPool2d((1,1))\n        \n        self.fc = nn.Linear(256, num_class)\n\n    def forward(self, x):\n        # x: (B, C, T, V)\n        B, C, T, V = x.shape\n        x = x.permute(0, 1, 3, 2).contiguous()  # (B, C, V, T) for bn\n        x = x.view(B, C * V, T)\n        x = self.data_bn(x)\n        x = x.view(B, C, V, T).permute(0, 1, 3, 2).contiguous()  # back to (B, C, T, V)\n    \n        for layer in self.layers:\n            x = layer(x)\n    \n        # ðŸ”¹ Apply temporal attention here\n        x = self.temporal_attn(x)\n    \n        # global pool\n        x = self.pool(x)  # (B, C_out, 1, 1)\n        x = x.view(B, -1)\n        out = self.fc(x)\n        return out\n\ndef mixup_data(x, y, alpha=1.0, device=None):\n    if alpha <= 0:\n        return x, y, 1.0, y\n    lam = np.random.beta(alpha, alpha)\n    batch_size = x.size(0)\n    index = torch.randperm(batch_size).to(device)\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\ndef accuracy_top1(output, target):\n    pred = output.argmax(dim=1)\n    return (pred == target).float().mean().item() * 100.0\n\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T06:38:52.371320Z","iopub.execute_input":"2025-09-26T06:38:52.371792Z","iopub.status.idle":"2025-09-26T06:38:52.389936Z","shell.execute_reply.started":"2025-09-26T06:38:52.371771Z","shell.execute_reply":"2025-09-26T06:38:52.389213Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def main():\n    # Datasets\n    preprocessor = LandmarkPreprocessor(augment=True, target_frames=T_FRAMES)\n    train_dataset = WLASLLandmarkDataset(LANDMARK_FILE, SPLIT_FILE, split='train', preprocessor=preprocessor)\n    val_dataset = WLASLLandmarkDataset(LANDMARK_FILE, SPLIT_FILE, split='val', preprocessor=preprocessor)\n    test_dataset = WLASLLandmarkDataset(LANDMARK_FILE, SPLIT_FILE, split='test', preprocessor=preprocessor)\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True, collate_fn=collate_fn)\n    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True, collate_fn=collate_fn)\n    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True, collate_fn=collate_fn)\n\n    # class weights\n    train_labels = [int(s['label']) for s in train_dataset.samples]\n    class_weights = compute_class_weight('balanced', classes=np.arange(NUM_CLASSES), y=train_labels)\n    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(DEVICE)\n\n    # model\n    model = STGCN(in_channels=C, num_class=NUM_CLASSES, num_nodes=TOTAL_LANDMARKS).to(DEVICE)\n    print(f\"Model has {count_parameters(model)} trainable parameters.\")\n    optimizer = torch.optim.AdamW(model.parameters(), lr=BASE_LR, weight_decay=WEIGHT_DECAY)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n\n    scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n\n    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor, label_smoothing=LABEL_SMOOTHING)\n\n    best_val = 0.0\n    train_history = {'epoch': [], 'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n    for epoch in range(EPOCHS):\n        model.train()\n        running_loss = 0.0\n        running_acc = 0.0\n        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} Train\")\n        for x, y in pbar:\n            x = x.to(DEVICE)  # (B, C, T, V)\n            y = y.to(DEVICE)\n            # mixup\n            if MIXUP_ALPHA > 0:\n                mixed_x, y_a, y_b, lam = mixup_data(x, y, alpha=MIXUP_ALPHA, device=DEVICE)\n            else:\n                mixed_x, y_a, y_b, lam = x, y, y, 1.0\n\n            optimizer.zero_grad()\n            with torch.cuda.amp.autocast(enabled=USE_AMP):\n                logits = model(mixed_x)\n                loss = lam * criterion(logits, y_a) + (1 - lam) * criterion(logits, y_b)\n            scaler.scale(loss).backward()\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            scaler.step(optimizer)\n            scaler.update()\n            running_loss += loss.item() * x.size(0)\n            running_acc += accuracy_top1(logits.detach().cpu(), y.detach().cpu()) * x.size(0) / 100.0\n            pbar.set_postfix(loss=running_loss / ((pbar.n + 1) * x.size(0)), acc=(running_acc / ((pbar.n + 1) * x.size(0)) * 100.0))\n\n        avg_train_loss = running_loss / len(train_dataset)\n        avg_train_acc = running_acc / len(train_dataset) * 100.0\n\n        # validation\n        model.eval()\n        val_loss = 0.0\n        val_acc = 0.0\n        with torch.no_grad():\n            for x, y in tqdm(val_loader, desc=\"Validation\"):\n                x = x.to(DEVICE); y = y.to(DEVICE)\n                with torch.cuda.amp.autocast(enabled=USE_AMP):\n                    logits = model(x)\n                    loss = criterion(logits, y)\n                val_loss += loss.item() * x.size(0)\n                val_acc += accuracy_top1(logits.detach().cpu(), y.detach().cpu()) * x.size(0) / 100.0\n        avg_val_loss = val_loss / len(val_dataset)\n        avg_val_acc = val_acc / len(val_dataset) * 100.0\n\n        scheduler.step(avg_val_loss)\n        print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss {avg_train_loss:.4f} Acc {avg_train_acc:.2f}% | Val Loss {avg_val_loss:.4f} Acc {avg_val_acc:.2f}%\")\n\n        train_history['epoch'].append(epoch+1)\n        train_history['train_loss'].append(avg_train_loss)\n        train_history['train_acc'].append(avg_train_acc)\n        train_history['val_loss'].append(avg_val_loss)\n        train_history['val_acc'].append(avg_val_acc)\n\n        if avg_val_acc > best_val:\n            best_val = avg_val_acc\n            torch.save(model.state_dict(), f\"best_stgcn_{NUM_CLASSES}.pth\")\n            print(f\"âœ… New best model: {best_val:.2f}%\")\n\n    print(\"Training complete. Best val:\", best_val)\n\n    # Save log to CSV\n    df = pd.DataFrame(train_history)\n    df.to_csv('training_log.csv', index=False)\n    print(\"Training log saved to training_log.csv\")\n\n    # Plot\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(df['epoch'], df['train_loss'], label='Train Loss')\n    plt.plot(df['epoch'], df['val_loss'], label='Val Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.title('Loss Curve')\n    plt.subplot(1, 2, 2)\n    plt.plot(df['epoch'], df['train_acc'], label='Train Acc')\n    plt.plot(df['epoch'], df['val_acc'], label='Val Acc')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.legend()\n    plt.title('Accuracy Curve')\n    plt.savefig('training_curves.png')\n    plt.close()\n    print(\"Training curves saved to training_curves.png\")\n\n    # Test\n    model.load_state_dict(torch.load(f\"best_stgcn_{NUM_CLASSES}.pth\"))\n    model.eval()\n    test_acc = 0.0\n    with torch.no_grad():\n        for x, y in tqdm(test_loader, desc=\"Testing\"):\n            x = x.to(DEVICE); y = y.to(DEVICE)\n            with torch.cuda.amp.autocast(enabled=USE_AMP):\n                logits = model(x)\n            test_acc += accuracy_top1(logits.detach().cpu(), y.detach().cpu()) * x.size(0) / 100.0\n    avg_test_acc = test_acc / len(test_dataset) * 100.0\n    print(f\"Final Test Accuracy: {avg_test_acc:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T06:38:53.092165Z","iopub.execute_input":"2025-09-26T06:38:53.092416Z","iopub.status.idle":"2025-09-26T06:38:53.110647Z","shell.execute_reply.started":"2025-09-26T06:38:53.092400Z","shell.execute_reply":"2025-09-26T06:38:53.110042Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T06:38:54.040562Z","iopub.execute_input":"2025-09-26T06:38:54.041198Z","execution_failed":"2025-09-26T12:03:00.470Z"}},"outputs":[{"name":"stdout","text":"âœ… Created 'train' split with 3549 samples.\nâœ… Created 'val' split with 901 samples.\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/1706839668.py:22: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n","output_type":"stream"},{"name":"stdout","text":"âœ… Created 'test' split with 668 samples.\nModel has 1260776 trainable parameters.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/350 Train:   0%|          | 0/111 [00:00<?, ?it/s]/tmp/ipykernel_36/1706839668.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=USE_AMP):\nEpoch 1/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=0.373, loss=6.29]\nValidation:   0%|          | 0/29 [00:00<?, ?it/s]/tmp/ipykernel_36/1706839668.py:65: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=USE_AMP):\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.38it/s]\n/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/350 | Train Loss 5.7042 Acc 0.34% | Val Loss 5.4844 Acc 1.44%\nâœ… New best model: 1.44%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:53<00:00,  2.09it/s, acc=0.777, loss=6.01]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/350 | Train Loss 5.4551 Acc 0.70% | Val Loss 5.2210 Acc 3.11%\nâœ… New best model: 3.11%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:53<00:00,  2.09it/s, acc=1.12, loss=5.82] \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/350 | Train Loss 5.2744 Acc 1.01% | Val Loss 5.0531 Acc 4.55%\nâœ… New best model: 4.55%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:53<00:00,  2.07it/s, acc=2.49, loss=5.64]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/350 | Train Loss 5.1190 Acc 2.25% | Val Loss 4.9027 Acc 6.44%\nâœ… New best model: 6.44%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=3.63, loss=5.48]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/350 | Train Loss 4.9677 Acc 3.30% | Val Loss 4.6892 Acc 7.88%\nâœ… New best model: 7.88%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=5.56, loss=5.3] \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/350 | Train Loss 4.8087 Acc 5.04% | Val Loss 4.5252 Acc 10.99%\nâœ… New best model: 10.99%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=8.08, loss=5.13]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/350 | Train Loss 4.6534 Acc 7.33% | Val Loss 4.3144 Acc 14.65%\nâœ… New best model: 14.65%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:53<00:00,  2.09it/s, acc=9.88, loss=4.99]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/350 | Train Loss 4.5245 Acc 8.96% | Val Loss 4.2263 Acc 16.87%\nâœ… New best model: 16.87%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=12.6, loss=4.75]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/350 | Train Loss 4.3096 Acc 11.44% | Val Loss 3.8895 Acc 23.42%\nâœ… New best model: 23.42%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=14.4, loss=4.58]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/350 | Train Loss 4.1567 Acc 13.02% | Val Loss 3.7187 Acc 28.75%\nâœ… New best model: 28.75%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=18, loss=4.41]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11/350 | Train Loss 3.9982 Acc 16.31% | Val Loss 3.5871 Acc 29.63%\nâœ… New best model: 29.63%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=21.9, loss=4.23]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12/350 | Train Loss 3.8403 Acc 19.84% | Val Loss 3.4691 Acc 33.74%\nâœ… New best model: 33.74%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=21.1, loss=4.12]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13/350 | Train Loss 3.7388 Acc 19.10% | Val Loss 3.3075 Acc 38.62%\nâœ… New best model: 38.62%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=23, loss=4.07]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14/350 | Train Loss 3.6934 Acc 20.88% | Val Loss 3.2470 Acc 40.51%\nâœ… New best model: 40.51%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=20.8, loss=3.83]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15/350 | Train Loss 3.4700 Acc 18.88% | Val Loss 3.1209 Acc 41.40%\nâœ… New best model: 41.40%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=24.1, loss=3.68]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16/350 | Train Loss 3.3391 Acc 21.87% | Val Loss 3.0655 Acc 41.73%\nâœ… New best model: 41.73%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.10it/s, acc=32.9, loss=3.5] \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17/350 | Train Loss 3.1743 Acc 29.81% | Val Loss 3.0071 Acc 45.73%\nâœ… New best model: 45.73%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=31.1, loss=3.5] \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18/350 | Train Loss 3.1769 Acc 28.23% | Val Loss 2.8728 Acc 46.95%\nâœ… New best model: 46.95%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=38.4, loss=3.36]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19/350 | Train Loss 3.0438 Acc 34.83% | Val Loss 2.8090 Acc 49.28%\nâœ… New best model: 49.28%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=33.9, loss=3.42]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20/350 | Train Loss 3.0979 Acc 30.77% | Val Loss 2.7576 Acc 50.17%\nâœ… New best model: 50.17%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=34, loss=3.45]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21/350 | Train Loss 3.1309 Acc 30.88% | Val Loss 2.7287 Acc 50.39%\nâœ… New best model: 50.39%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=39.5, loss=3.24]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22/350 | Train Loss 2.9413 Acc 35.84% | Val Loss 2.7507 Acc 50.17%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=40.5, loss=3.1] \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23/350 | Train Loss 2.8159 Acc 36.71% | Val Loss 2.6716 Acc 52.83%\nâœ… New best model: 52.83%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=41.5, loss=3.07]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24/350 | Train Loss 2.7855 Acc 37.62% | Val Loss 2.5478 Acc 55.83%\nâœ… New best model: 55.83%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.10it/s, acc=42.4, loss=3.1] \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25/350 | Train Loss 2.8088 Acc 38.43% | Val Loss 2.5461 Acc 57.49%\nâœ… New best model: 57.49%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=48.6, loss=2.99]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26/350 | Train Loss 2.7123 Acc 44.07% | Val Loss 2.5357 Acc 56.38%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=40.2, loss=2.93]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27/350 | Train Loss 2.6573 Acc 36.46% | Val Loss 2.4937 Acc 57.82%\nâœ… New best model: 57.82%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.16it/s, acc=45.2, loss=2.81]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28/350 | Train Loss 2.5446 Acc 41.03% | Val Loss 2.5247 Acc 56.71%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=37.7, loss=2.97]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29/350 | Train Loss 2.6904 Acc 34.23% | Val Loss 2.4810 Acc 59.60%\nâœ… New best model: 59.60%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=44.2, loss=2.69]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30/350 | Train Loss 2.4403 Acc 40.10% | Val Loss 2.4757 Acc 59.27%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=44, loss=2.84]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 31/350 | Train Loss 2.5796 Acc 39.90% | Val Loss 2.4373 Acc 59.93%\nâœ… New best model: 59.93%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 32/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=51.3, loss=2.62]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 32/350 | Train Loss 2.3803 Acc 46.55% | Val Loss 2.3955 Acc 61.27%\nâœ… New best model: 61.27%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 33/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=47.3, loss=2.46]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 33/350 | Train Loss 2.2309 Acc 42.89% | Val Loss 2.3816 Acc 60.60%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 34/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=50, loss=2.6]   \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 34/350 | Train Loss 2.3622 Acc 45.34% | Val Loss 2.4162 Acc 61.93%\nâœ… New best model: 61.93%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 35/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=43.4, loss=2.9] \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 35/350 | Train Loss 2.6299 Acc 39.36% | Val Loss 2.3955 Acc 62.60%\nâœ… New best model: 62.60%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=45.5, loss=2.9] \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 36/350 | Train Loss 2.6308 Acc 41.25% | Val Loss 2.4246 Acc 60.49%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 37/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=44.2, loss=2.75]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 37/350 | Train Loss 2.4898 Acc 40.10% | Val Loss 2.3968 Acc 61.15%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 38/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=46.3, loss=2.63]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 38/350 | Train Loss 2.3825 Acc 41.96% | Val Loss 2.3180 Acc 62.93%\nâœ… New best model: 62.93%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 39/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.16it/s, acc=52.1, loss=2.56]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 39/350 | Train Loss 2.3190 Acc 47.22% | Val Loss 2.3642 Acc 62.38%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 40/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.17it/s, acc=47.8, loss=2.45]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 40/350 | Train Loss 2.2225 Acc 43.34% | Val Loss 2.3507 Acc 63.37%\nâœ… New best model: 63.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 41/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.17it/s, acc=55.1, loss=2.65]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 41/350 | Train Loss 2.4006 Acc 49.96% | Val Loss 2.3312 Acc 63.71%\nâœ… New best model: 63.71%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 42/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=53.2, loss=2.47]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 42/350 | Train Loss 2.2386 Acc 48.30% | Val Loss 2.3590 Acc 62.38%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 43/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=56.4, loss=2.54]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 43/350 | Train Loss 2.3021 Acc 51.17% | Val Loss 2.3558 Acc 62.49%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 44/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=45.3, loss=2.36]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 44/350 | Train Loss 2.1435 Acc 41.11% | Val Loss 2.3037 Acc 64.15%\nâœ… New best model: 64.15%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 45/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:50<00:00,  2.19it/s, acc=38.4, loss=2.53]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 45/350 | Train Loss 2.2959 Acc 34.80% | Val Loss 2.2919 Acc 64.37%\nâœ… New best model: 64.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 46/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=52.6, loss=2.49]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 46/350 | Train Loss 2.2561 Acc 47.70% | Val Loss 2.3491 Acc 63.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 47/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.16it/s, acc=57.2, loss=2.38]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 47/350 | Train Loss 2.1593 Acc 51.85% | Val Loss 2.3137 Acc 63.71%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 48/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=49.3, loss=2.33]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 48/350 | Train Loss 2.1171 Acc 44.72% | Val Loss 2.3019 Acc 65.48%\nâœ… New best model: 65.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 49/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=45, loss=2.44]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 49/350 | Train Loss 2.2114 Acc 40.77% | Val Loss 2.3129 Acc 64.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 50/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=49, loss=2.4]   \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 50/350 | Train Loss 2.1736 Acc 44.44% | Val Loss 2.2532 Acc 65.82%\nâœ… New best model: 65.82%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 51/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.16it/s, acc=48.6, loss=2.43]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 51/350 | Train Loss 2.2023 Acc 44.04% | Val Loss 2.3044 Acc 64.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 52/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=49.4, loss=2.42]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 52/350 | Train Loss 2.1950 Acc 44.77% | Val Loss 2.2941 Acc 66.59%\nâœ… New best model: 66.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 53/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=59.5, loss=2.46]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 53/350 | Train Loss 2.2342 Acc 53.96% | Val Loss 2.3003 Acc 65.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 54/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=45.9, loss=2.41]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 54/350 | Train Loss 2.1900 Acc 41.65% | Val Loss 2.3119 Acc 64.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 55/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.16it/s, acc=52, loss=2.2]   \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 55/350 | Train Loss 1.9939 Acc 47.20% | Val Loss 2.2843 Acc 66.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 56/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.16it/s, acc=51.6, loss=2.52]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 56/350 | Train Loss 2.2848 Acc 46.77% | Val Loss 2.2627 Acc 65.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 57/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=50.6, loss=2.29]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 57/350 | Train Loss 2.0748 Acc 45.90% | Val Loss 2.2841 Acc 65.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 58/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=53.5, loss=2.38]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 58/350 | Train Loss 2.1619 Acc 48.49% | Val Loss 2.3109 Acc 65.15%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 59/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=46.2, loss=2.26]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 59/350 | Train Loss 2.0511 Acc 41.90% | Val Loss 2.2526 Acc 67.59%\nâœ… New best model: 67.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 60/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.16it/s, acc=52.7, loss=2.25]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 60/350 | Train Loss 2.0434 Acc 47.76% | Val Loss 2.2739 Acc 65.82%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 61/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=54.6, loss=2.55]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 61/350 | Train Loss 2.3166 Acc 49.48% | Val Loss 2.2730 Acc 66.04%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 62/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=56.8, loss=2.18]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 62/350 | Train Loss 1.9748 Acc 51.56% | Val Loss 2.2441 Acc 65.93%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 63/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=59.5, loss=2.33]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 63/350 | Train Loss 2.1138 Acc 53.96% | Val Loss 2.3147 Acc 67.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 64/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=55.9, loss=2.23]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 64/350 | Train Loss 2.0197 Acc 50.69% | Val Loss 2.2390 Acc 68.48%\nâœ… New best model: 68.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 65/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=54.2, loss=2.3] \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 65/350 | Train Loss 2.0822 Acc 49.14% | Val Loss 2.2967 Acc 65.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 66/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.16it/s, acc=53.1, loss=2.22]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 66/350 | Train Loss 2.0153 Acc 48.15% | Val Loss 2.2568 Acc 66.93%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 67/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=49.1, loss=2.3] \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 67/350 | Train Loss 2.0904 Acc 44.55% | Val Loss 2.2461 Acc 66.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 68/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:53<00:00,  2.09it/s, acc=47.7, loss=2.47]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 68/350 | Train Loss 2.2412 Acc 43.22% | Val Loss 2.2514 Acc 66.04%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 69/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=50.7, loss=2.31]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 69/350 | Train Loss 2.0976 Acc 46.01% | Val Loss 2.2363 Acc 67.04%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 70/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=55.8, loss=2.27]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 70/350 | Train Loss 2.0603 Acc 50.63% | Val Loss 2.2573 Acc 67.81%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 71/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=60.1, loss=2.53]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 71/350 | Train Loss 2.2947 Acc 54.49% | Val Loss 2.2400 Acc 66.04%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 72/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=58.7, loss=2.31]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 72/350 | Train Loss 2.0922 Acc 53.20% | Val Loss 2.2644 Acc 68.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 73/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=50.3, loss=2.13]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 73/350 | Train Loss 1.9320 Acc 45.59% | Val Loss 2.2514 Acc 67.15%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 74/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=51.3, loss=2.26]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 74/350 | Train Loss 2.0514 Acc 46.49% | Val Loss 2.2475 Acc 67.15%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 75/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=58.7, loss=2.31]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 75/350 | Train Loss 2.0925 Acc 53.25% | Val Loss 2.2059 Acc 68.81%\nâœ… New best model: 68.81%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 76/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=47.1, loss=2.36]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 76/350 | Train Loss 2.1397 Acc 42.72% | Val Loss 2.2555 Acc 69.03%\nâœ… New best model: 69.03%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 77/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=51, loss=2.22]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 77/350 | Train Loss 2.0175 Acc 46.29% | Val Loss 2.2534 Acc 67.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 78/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=55.2, loss=2.19]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 78/350 | Train Loss 1.9819 Acc 50.04% | Val Loss 2.1999 Acc 69.48%\nâœ… New best model: 69.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 79/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.16it/s, acc=63, loss=2.3]   \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 79/350 | Train Loss 2.0879 Acc 57.14% | Val Loss 2.2538 Acc 68.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 80/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.16it/s, acc=55.7, loss=2.31]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 80/350 | Train Loss 2.0930 Acc 50.49% | Val Loss 2.2639 Acc 66.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 81/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=55, loss=2.23]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 81/350 | Train Loss 2.0188 Acc 49.87% | Val Loss 2.2527 Acc 67.81%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 82/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=59.3, loss=2.04]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 82/350 | Train Loss 1.8535 Acc 53.76% | Val Loss 2.2421 Acc 68.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 83/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=62.2, loss=2.16]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 83/350 | Train Loss 1.9635 Acc 56.44% | Val Loss 2.2217 Acc 68.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 84/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=56.9, loss=2.05]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 84/350 | Train Loss 1.8633 Acc 51.59% | Val Loss 2.2355 Acc 69.15%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 85/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=63.8, loss=2.19]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 85/350 | Train Loss 1.9869 Acc 57.85% | Val Loss 2.2510 Acc 68.04%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 86/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.16it/s, acc=55.1, loss=2.29]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 86/350 | Train Loss 2.0795 Acc 49.99% | Val Loss 2.2414 Acc 68.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 87/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=53.7, loss=2.31]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 87/350 | Train Loss 2.0910 Acc 48.72% | Val Loss 2.2754 Acc 66.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 88/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=54.6, loss=2.43]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 88/350 | Train Loss 2.2001 Acc 49.51% | Val Loss 2.2444 Acc 67.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 89/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=54, loss=2.14]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 89/350 | Train Loss 1.9434 Acc 49.00% | Val Loss 2.2287 Acc 68.81%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 90/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=54.5, loss=2.26]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:13<00:00,  2.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 90/350 | Train Loss 2.0454 Acc 49.45% | Val Loss 2.2372 Acc 69.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 91/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=53.5, loss=2.25]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 91/350 | Train Loss 2.0447 Acc 48.52% | Val Loss 2.2048 Acc 69.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 92/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.17it/s, acc=56.3, loss=2.32]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 92/350 | Train Loss 2.1082 Acc 51.08% | Val Loss 2.2079 Acc 68.15%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 93/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.16it/s, acc=49.1, loss=2.25]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 93/350 | Train Loss 2.0406 Acc 44.52% | Val Loss 2.2135 Acc 69.15%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 94/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.17it/s, acc=52.1, loss=2.11]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 94/350 | Train Loss 1.9128 Acc 47.22% | Val Loss 2.2266 Acc 66.15%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 95/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.16it/s, acc=56.9, loss=2.3] \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 95/350 | Train Loss 2.0866 Acc 51.59% | Val Loss 2.2368 Acc 67.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 96/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:50<00:00,  2.19it/s, acc=62.4, loss=2.21]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 96/350 | Train Loss 2.0073 Acc 56.58% | Val Loss 2.1808 Acc 68.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 97/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.16it/s, acc=46.9, loss=2.14]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 97/350 | Train Loss 1.9381 Acc 42.52% | Val Loss 2.2051 Acc 69.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 98/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.17it/s, acc=52.7, loss=2.11]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 98/350 | Train Loss 1.9097 Acc 47.82% | Val Loss 2.2441 Acc 69.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 99/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.16it/s, acc=44.9, loss=2.29]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 99/350 | Train Loss 2.0791 Acc 40.74% | Val Loss 2.1862 Acc 67.70%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 100/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.16it/s, acc=59.2, loss=2.13]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 100/350 | Train Loss 1.9290 Acc 53.68% | Val Loss 2.2291 Acc 68.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 101/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=52.2, loss=2.35]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 101/350 | Train Loss 2.1304 Acc 47.34% | Val Loss 2.1919 Acc 68.70%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 102/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=53, loss=2.23]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 102/350 | Train Loss 2.0208 Acc 48.10% | Val Loss 2.2431 Acc 67.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 103/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.16it/s, acc=58.2, loss=2.12]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 103/350 | Train Loss 1.9263 Acc 52.83% | Val Loss 2.1972 Acc 68.04%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 104/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=53.1, loss=2.28]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 104/350 | Train Loss 2.0706 Acc 48.18% | Val Loss 2.2169 Acc 70.03%\nâœ… New best model: 70.03%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 105/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.17it/s, acc=60, loss=2.11]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 105/350 | Train Loss 1.9172 Acc 54.47% | Val Loss 2.1942 Acc 69.15%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 106/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=54.2, loss=2.2] \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 106/350 | Train Loss 1.9938 Acc 49.20% | Val Loss 2.2106 Acc 68.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 107/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=59.1, loss=2.1] \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 107/350 | Train Loss 1.9041 Acc 53.56% | Val Loss 2.1946 Acc 70.26%\nâœ… New best model: 70.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 108/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=53.8, loss=2.18]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 108/350 | Train Loss 1.9770 Acc 48.77% | Val Loss 2.2295 Acc 68.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 109/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=52.7, loss=2.32]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 109/350 | Train Loss 2.1035 Acc 47.82% | Val Loss 2.2059 Acc 68.15%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 110/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=45.8, loss=2.45]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 110/350 | Train Loss 2.2265 Acc 41.50% | Val Loss 2.2185 Acc 68.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 111/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.13it/s, acc=47.1, loss=2.34]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 111/350 | Train Loss 2.1196 Acc 42.74% | Val Loss 2.1817 Acc 69.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 112/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=55.1, loss=2.29]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 112/350 | Train Loss 2.0774 Acc 50.01% | Val Loss 2.2287 Acc 68.81%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 113/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=55.2, loss=2.16]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 113/350 | Train Loss 1.9629 Acc 50.07% | Val Loss 2.2288 Acc 68.81%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 114/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=48.6, loss=2.13]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 114/350 | Train Loss 1.9318 Acc 44.10% | Val Loss 2.1944 Acc 68.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 115/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=59.5, loss=2.14]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 115/350 | Train Loss 1.9402 Acc 53.93% | Val Loss 2.1923 Acc 69.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 116/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=50.4, loss=2.14]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 116/350 | Train Loss 1.9435 Acc 45.70% | Val Loss 2.2255 Acc 68.04%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 117/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=54.7, loss=2.26]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 117/350 | Train Loss 2.0525 Acc 49.65% | Val Loss 2.1949 Acc 69.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 118/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=49.4, loss=2.08]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 118/350 | Train Loss 1.8882 Acc 44.80% | Val Loss 2.1931 Acc 69.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 119/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:53<00:00,  2.09it/s, acc=52.4, loss=2.14]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 119/350 | Train Loss 1.9449 Acc 47.51% | Val Loss 2.2283 Acc 69.15%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 120/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=48.9, loss=2.23]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 120/350 | Train Loss 2.0262 Acc 44.38% | Val Loss 2.2121 Acc 69.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 121/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=55.5, loss=2.01]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 121/350 | Train Loss 1.8209 Acc 50.35% | Val Loss 2.1981 Acc 68.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 122/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=47.5, loss=2.04]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 122/350 | Train Loss 1.8478 Acc 43.11% | Val Loss 2.2164 Acc 69.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 123/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=55, loss=2.24]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 123/350 | Train Loss 2.0292 Acc 49.90% | Val Loss 2.1830 Acc 70.26%\nâœ… New best model: 70.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 124/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=49.3, loss=2.06]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 124/350 | Train Loss 1.8675 Acc 44.74% | Val Loss 2.1515 Acc 68.81%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 125/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=53.6, loss=2.25]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 125/350 | Train Loss 2.0434 Acc 48.63% | Val Loss 2.1905 Acc 69.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 126/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.10it/s, acc=49.5, loss=2.16]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 126/350 | Train Loss 1.9560 Acc 44.89% | Val Loss 2.2071 Acc 69.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 127/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=51.9, loss=2.06]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 127/350 | Train Loss 1.8656 Acc 47.06% | Val Loss 2.1683 Acc 70.03%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 128/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.10it/s, acc=49.9, loss=2.09]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 128/350 | Train Loss 1.8915 Acc 45.28% | Val Loss 2.1776 Acc 70.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 129/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=47.2, loss=2.19]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 129/350 | Train Loss 1.9887 Acc 42.80% | Val Loss 2.2121 Acc 67.15%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 130/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=47.9, loss=2.24]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 130/350 | Train Loss 2.0284 Acc 43.42% | Val Loss 2.1857 Acc 69.92%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 131/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=62.2, loss=2.11]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 131/350 | Train Loss 1.9105 Acc 56.44% | Val Loss 2.2051 Acc 69.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 132/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=63.5, loss=2.12]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 132/350 | Train Loss 1.9227 Acc 57.62% | Val Loss 2.1665 Acc 68.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 133/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.16it/s, acc=56.2, loss=2.16]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 133/350 | Train Loss 1.9616 Acc 51.00% | Val Loss 2.2075 Acc 68.81%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 134/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=57.6, loss=2.08]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 134/350 | Train Loss 1.8872 Acc 52.24% | Val Loss 2.1558 Acc 69.15%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 135/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=52.7, loss=2.13]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 135/350 | Train Loss 1.9279 Acc 47.84% | Val Loss 2.2000 Acc 68.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 136/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=59.7, loss=2.16]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 136/350 | Train Loss 1.9563 Acc 54.13% | Val Loss 2.2041 Acc 69.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 137/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=52.3, loss=2.23]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 137/350 | Train Loss 2.0263 Acc 47.45% | Val Loss 2.2068 Acc 68.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 138/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=53.9, loss=2.02]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 138/350 | Train Loss 1.8298 Acc 48.92% | Val Loss 2.2048 Acc 67.92%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 139/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=53, loss=2.01]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 139/350 | Train Loss 1.8250 Acc 48.07% | Val Loss 2.1692 Acc 70.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 140/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=54.8, loss=2.24]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 140/350 | Train Loss 2.0355 Acc 49.73% | Val Loss 2.1764 Acc 69.03%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 141/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=58.6, loss=2.3] \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 141/350 | Train Loss 2.0878 Acc 53.17% | Val Loss 2.2165 Acc 68.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 142/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=49.2, loss=2.1] \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 142/350 | Train Loss 1.9086 Acc 44.60% | Val Loss 2.2123 Acc 69.70%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 143/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=54.5, loss=2.25]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 143/350 | Train Loss 2.0373 Acc 49.42% | Val Loss 2.2381 Acc 68.15%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 144/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=52.2, loss=2.17]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 144/350 | Train Loss 1.9659 Acc 47.37% | Val Loss 2.1988 Acc 69.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 145/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.10it/s, acc=56.3, loss=2.1] \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 145/350 | Train Loss 1.9028 Acc 51.06% | Val Loss 2.1595 Acc 70.37%\nâœ… New best model: 70.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 146/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=52.5, loss=2.23]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 146/350 | Train Loss 2.0229 Acc 47.65% | Val Loss 2.1756 Acc 69.81%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 147/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=56, loss=2.06]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 147/350 | Train Loss 1.8655 Acc 50.83% | Val Loss 2.2110 Acc 69.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 148/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=46.7, loss=2.13]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 148/350 | Train Loss 1.9336 Acc 42.38% | Val Loss 2.1361 Acc 70.14%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 149/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=61.9, loss=2.15]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 149/350 | Train Loss 1.9534 Acc 56.18% | Val Loss 2.1913 Acc 68.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 150/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=50, loss=2.15]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 150/350 | Train Loss 1.9533 Acc 45.39% | Val Loss 2.1794 Acc 70.14%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 151/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=54.4, loss=2.12]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 151/350 | Train Loss 1.9233 Acc 49.34% | Val Loss 2.1869 Acc 70.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 152/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=53.4, loss=2.09]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 152/350 | Train Loss 1.8961 Acc 48.41% | Val Loss 2.1940 Acc 69.70%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 153/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=49, loss=2.07]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 153/350 | Train Loss 1.8797 Acc 44.46% | Val Loss 2.1538 Acc 69.03%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 154/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=54.4, loss=2.12]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 154/350 | Train Loss 1.9249 Acc 49.34% | Val Loss 2.1802 Acc 68.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 155/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.10it/s, acc=48.6, loss=2.17]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 155/350 | Train Loss 1.9666 Acc 44.10% | Val Loss 2.1424 Acc 69.15%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 156/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=48.5, loss=2.09]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 156/350 | Train Loss 1.8999 Acc 44.01% | Val Loss 2.1824 Acc 69.70%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 157/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=58.5, loss=2.05]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 157/350 | Train Loss 1.8617 Acc 53.06% | Val Loss 2.2012 Acc 68.70%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 158/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:53<00:00,  2.09it/s, acc=54.2, loss=2.05]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 158/350 | Train Loss 1.8620 Acc 49.14% | Val Loss 2.1649 Acc 69.70%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 159/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:53<00:00,  2.09it/s, acc=56.1, loss=2.28]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 159/350 | Train Loss 2.0659 Acc 50.89% | Val Loss 2.1811 Acc 69.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 160/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:53<00:00,  2.09it/s, acc=55.3, loss=2.07]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 160/350 | Train Loss 1.8754 Acc 50.15% | Val Loss 2.2068 Acc 69.15%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 161/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:53<00:00,  2.09it/s, acc=58.2, loss=2.09]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 161/350 | Train Loss 1.8983 Acc 52.80% | Val Loss 2.1588 Acc 69.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 162/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.10it/s, acc=60.5, loss=2.13]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 162/350 | Train Loss 1.9342 Acc 54.89% | Val Loss 2.1881 Acc 69.70%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 163/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:53<00:00,  2.09it/s, acc=61.6, loss=1.96]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 163/350 | Train Loss 1.7783 Acc 55.90% | Val Loss 2.1928 Acc 69.03%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 164/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=56.8, loss=1.94]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 164/350 | Train Loss 1.7634 Acc 51.48% | Val Loss 2.2011 Acc 69.03%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 165/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=53.7, loss=2.19]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 165/350 | Train Loss 1.9867 Acc 48.75% | Val Loss 2.1747 Acc 70.03%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 166/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=62.3, loss=2.06]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 166/350 | Train Loss 1.8691 Acc 56.47% | Val Loss 2.1627 Acc 69.70%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 167/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=57.5, loss=1.99]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 167/350 | Train Loss 1.8034 Acc 52.16% | Val Loss 2.2047 Acc 68.81%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 168/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=45.9, loss=2.16]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 168/350 | Train Loss 1.9624 Acc 41.59% | Val Loss 2.1821 Acc 70.59%\nâœ… New best model: 70.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 169/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=47.2, loss=2.1] \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 169/350 | Train Loss 1.9063 Acc 42.77% | Val Loss 2.1757 Acc 68.81%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 170/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=60.2, loss=2.19]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 170/350 | Train Loss 1.9833 Acc 54.64% | Val Loss 2.1721 Acc 70.59%\nâœ… New best model: 70.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 171/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=56.3, loss=2.06]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 171/350 | Train Loss 1.8722 Acc 51.06% | Val Loss 2.1715 Acc 69.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 172/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=64.6, loss=2.08]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 172/350 | Train Loss 1.8889 Acc 58.55% | Val Loss 2.2034 Acc 68.70%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 173/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=56.3, loss=2.08]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 173/350 | Train Loss 1.8883 Acc 51.03% | Val Loss 2.1624 Acc 69.03%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 174/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=53.8, loss=2.1] \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 174/350 | Train Loss 1.9079 Acc 48.83% | Val Loss 2.1689 Acc 69.92%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 175/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=53.5, loss=2.1] \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 175/350 | Train Loss 1.9018 Acc 48.55% | Val Loss 2.1819 Acc 68.81%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 176/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=52.2, loss=2.11]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 176/350 | Train Loss 1.9096 Acc 47.34% | Val Loss 2.1596 Acc 71.48%\nâœ… New best model: 71.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 177/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=55.5, loss=2.05]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 177/350 | Train Loss 1.8595 Acc 50.38% | Val Loss 2.1430 Acc 71.25%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 178/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=48, loss=2.13]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 178/350 | Train Loss 1.9293 Acc 43.56% | Val Loss 2.1470 Acc 70.03%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 179/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=63.1, loss=2.07]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 179/350 | Train Loss 1.8820 Acc 57.23% | Val Loss 2.1576 Acc 69.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 180/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=56.1, loss=2.09]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 180/350 | Train Loss 1.8932 Acc 50.92% | Val Loss 2.1728 Acc 71.59%\nâœ… New best model: 71.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 181/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=58.2, loss=2.15]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 181/350 | Train Loss 1.9470 Acc 52.83% | Val Loss 2.1784 Acc 70.14%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 182/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=63.1, loss=2.09]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 182/350 | Train Loss 1.8930 Acc 57.26% | Val Loss 2.1813 Acc 70.81%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 183/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=55.4, loss=2.34]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 183/350 | Train Loss 2.1202 Acc 50.21% | Val Loss 2.1672 Acc 70.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 184/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=56, loss=2.02]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 184/350 | Train Loss 1.8286 Acc 50.77% | Val Loss 2.1828 Acc 70.14%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 185/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=52.3, loss=2.08]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 185/350 | Train Loss 1.8864 Acc 47.39% | Val Loss 2.1819 Acc 70.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 186/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=57.7, loss=2.12]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 186/350 | Train Loss 1.9254 Acc 52.32% | Val Loss 2.1946 Acc 69.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 187/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=56.9, loss=2.02]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 187/350 | Train Loss 1.8344 Acc 51.59% | Val Loss 2.1782 Acc 70.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 188/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=55.9, loss=2.01]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 188/350 | Train Loss 1.8249 Acc 50.66% | Val Loss 2.1583 Acc 70.03%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 189/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=49, loss=2]     \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 189/350 | Train Loss 1.8173 Acc 44.46% | Val Loss 2.1795 Acc 69.15%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 190/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=56.2, loss=2.02]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 190/350 | Train Loss 1.8282 Acc 50.97% | Val Loss 2.1432 Acc 71.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 191/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=54.7, loss=2.11]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 191/350 | Train Loss 1.9164 Acc 49.62% | Val Loss 2.1741 Acc 69.92%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 192/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=50.9, loss=2.14]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 192/350 | Train Loss 1.9429 Acc 46.21% | Val Loss 2.1880 Acc 70.81%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 193/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=60.8, loss=2.02]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 193/350 | Train Loss 1.8303 Acc 55.14% | Val Loss 2.1769 Acc 71.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 194/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=60.1, loss=2.14]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 194/350 | Train Loss 1.9384 Acc 54.52% | Val Loss 2.1789 Acc 69.92%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 195/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=52.7, loss=2.03]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 195/350 | Train Loss 1.8457 Acc 47.79% | Val Loss 2.1935 Acc 69.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 196/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=42.4, loss=2.1] \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 196/350 | Train Loss 1.9090 Acc 38.49% | Val Loss 2.1611 Acc 70.70%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 197/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=54.3, loss=2.09]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 197/350 | Train Loss 1.8913 Acc 49.28% | Val Loss 2.1231 Acc 71.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 198/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=57.8, loss=1.98]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 198/350 | Train Loss 1.7918 Acc 52.38% | Val Loss 2.1423 Acc 70.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 199/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.10it/s, acc=61.2, loss=2.01]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 199/350 | Train Loss 1.8222 Acc 55.54% | Val Loss 2.1817 Acc 70.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 200/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.09it/s, acc=51.6, loss=2.15]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 200/350 | Train Loss 1.9534 Acc 46.77% | Val Loss 2.1780 Acc 70.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 201/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:53<00:00,  2.09it/s, acc=58.9, loss=2.18]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 201/350 | Train Loss 1.9738 Acc 53.40% | Val Loss 2.1780 Acc 70.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 202/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=57.6, loss=2.07]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 202/350 | Train Loss 1.8801 Acc 52.21% | Val Loss 2.1764 Acc 70.14%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 203/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:53<00:00,  2.09it/s, acc=62.9, loss=2.16]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 203/350 | Train Loss 1.9597 Acc 57.06% | Val Loss 2.1648 Acc 71.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 204/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=57.3, loss=2.08]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 204/350 | Train Loss 1.8865 Acc 51.99% | Val Loss 2.1862 Acc 69.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 205/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=49.9, loss=2.11]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 205/350 | Train Loss 1.9127 Acc 45.25% | Val Loss 2.1542 Acc 69.81%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 206/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=59.8, loss=2.18]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 206/350 | Train Loss 1.9750 Acc 54.21% | Val Loss 2.1980 Acc 70.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 207/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=56.4, loss=2.14]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 207/350 | Train Loss 1.9368 Acc 51.20% | Val Loss 2.1349 Acc 71.03%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 208/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=56.5, loss=2.14]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 208/350 | Train Loss 1.9447 Acc 51.25% | Val Loss 2.1705 Acc 70.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 209/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=55.5, loss=1.95]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 209/350 | Train Loss 1.7696 Acc 50.30% | Val Loss 2.1895 Acc 70.03%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 210/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=47.7, loss=2.2] \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 210/350 | Train Loss 1.9965 Acc 43.28% | Val Loss 2.1356 Acc 71.81%\nâœ… New best model: 71.81%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 211/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=51.6, loss=2.04]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 211/350 | Train Loss 1.8527 Acc 46.77% | Val Loss 2.1656 Acc 70.03%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 212/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=56.6, loss=1.91]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 212/350 | Train Loss 1.7363 Acc 51.31% | Val Loss 2.1570 Acc 70.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 213/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=50.5, loss=2.05]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 213/350 | Train Loss 1.8583 Acc 45.76% | Val Loss 2.1644 Acc 70.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 214/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=63.3, loss=2.04]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 214/350 | Train Loss 1.8534 Acc 57.42% | Val Loss 2.1658 Acc 70.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 215/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=59.5, loss=1.96]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 215/350 | Train Loss 1.7740 Acc 53.96% | Val Loss 2.1966 Acc 70.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 216/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=63.7, loss=1.94]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 216/350 | Train Loss 1.7620 Acc 57.82% | Val Loss 2.1613 Acc 71.25%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 217/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=48.2, loss=2.1] \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 217/350 | Train Loss 1.9016 Acc 43.67% | Val Loss 2.1599 Acc 70.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 218/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=50.1, loss=2.04]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 218/350 | Train Loss 1.8508 Acc 45.45% | Val Loss 2.1538 Acc 70.92%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 219/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.16it/s, acc=55, loss=1.97]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 219/350 | Train Loss 1.7888 Acc 49.85% | Val Loss 2.1641 Acc 70.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 220/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=61.8, loss=2.01]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 220/350 | Train Loss 1.8194 Acc 56.02% | Val Loss 2.1365 Acc 71.03%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 221/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=54.2, loss=2.08]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 221/350 | Train Loss 1.8841 Acc 49.20% | Val Loss 2.1963 Acc 70.92%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 222/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=54.6, loss=2.03]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 222/350 | Train Loss 1.8446 Acc 49.51% | Val Loss 2.1920 Acc 69.70%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 223/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=53.6, loss=2.18]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 223/350 | Train Loss 1.9776 Acc 48.58% | Val Loss 2.1790 Acc 69.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 224/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=54.6, loss=2.05]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 224/350 | Train Loss 1.8609 Acc 49.56% | Val Loss 2.1786 Acc 70.03%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 225/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=55.5, loss=2.18]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 225/350 | Train Loss 1.9741 Acc 50.35% | Val Loss 2.1793 Acc 69.92%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 226/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=63.3, loss=2]   \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 226/350 | Train Loss 1.8101 Acc 57.42% | Val Loss 2.1570 Acc 70.14%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 227/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=48.5, loss=2.1] \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 227/350 | Train Loss 1.9061 Acc 44.01% | Val Loss 2.1651 Acc 70.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 228/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:50<00:00,  2.18it/s, acc=50.9, loss=1.96]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 228/350 | Train Loss 1.7751 Acc 46.18% | Val Loss 2.1877 Acc 70.81%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 229/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=56.9, loss=2.01]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 229/350 | Train Loss 1.8211 Acc 51.62% | Val Loss 2.1877 Acc 71.03%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 230/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=59.7, loss=2.18]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 230/350 | Train Loss 1.9749 Acc 54.18% | Val Loss 2.1430 Acc 71.03%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 231/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=58.9, loss=2.09]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 231/350 | Train Loss 1.8969 Acc 53.40% | Val Loss 2.1860 Acc 70.81%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 232/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=49.8, loss=1.94]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 232/350 | Train Loss 1.7595 Acc 45.20% | Val Loss 2.1890 Acc 69.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 233/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=56.8, loss=1.94]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 233/350 | Train Loss 1.7570 Acc 51.56% | Val Loss 2.1393 Acc 70.92%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 234/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=54.5, loss=1.99]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 234/350 | Train Loss 1.8089 Acc 49.42% | Val Loss 2.1492 Acc 69.81%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 235/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=55, loss=2.17]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 235/350 | Train Loss 1.9704 Acc 49.85% | Val Loss 2.1843 Acc 70.81%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 236/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.17it/s, acc=59.7, loss=2.08]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 236/350 | Train Loss 1.8911 Acc 54.16% | Val Loss 2.1448 Acc 71.03%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 237/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=54.6, loss=2.15]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 237/350 | Train Loss 1.9505 Acc 49.51% | Val Loss 2.1539 Acc 70.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 238/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=52.5, loss=1.98]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 238/350 | Train Loss 1.7917 Acc 47.62% | Val Loss 2.1622 Acc 71.14%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 239/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.16it/s, acc=64.1, loss=2.11]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 239/350 | Train Loss 1.9138 Acc 58.13% | Val Loss 2.1825 Acc 70.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 240/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=44.7, loss=2.06]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 240/350 | Train Loss 1.8688 Acc 40.55% | Val Loss 2.1574 Acc 70.92%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 241/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=59.7, loss=1.98]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 241/350 | Train Loss 1.7936 Acc 54.13% | Val Loss 2.1370 Acc 71.14%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 242/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=55, loss=2.13]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 242/350 | Train Loss 1.9303 Acc 49.90% | Val Loss 2.1752 Acc 70.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 243/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=60.3, loss=1.95]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 243/350 | Train Loss 1.7680 Acc 54.69% | Val Loss 2.1491 Acc 70.92%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 244/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=54.3, loss=1.95]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 244/350 | Train Loss 1.7685 Acc 49.23% | Val Loss 2.1539 Acc 71.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 245/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=49.2, loss=1.99]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 245/350 | Train Loss 1.8048 Acc 44.60% | Val Loss 2.1791 Acc 70.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 246/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.16it/s, acc=54.4, loss=2.11]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 246/350 | Train Loss 1.9141 Acc 49.34% | Val Loss 2.1701 Acc 69.92%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 247/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=61.8, loss=2.02]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 247/350 | Train Loss 1.8334 Acc 56.02% | Val Loss 2.2027 Acc 71.70%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 248/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=54.6, loss=2.06]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 248/350 | Train Loss 1.8675 Acc 49.51% | Val Loss 2.1283 Acc 72.59%\nâœ… New best model: 72.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 249/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=56.6, loss=2.03]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 249/350 | Train Loss 1.8404 Acc 51.37% | Val Loss 2.1785 Acc 70.92%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 250/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=60.5, loss=2.09]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 250/350 | Train Loss 1.8969 Acc 54.83% | Val Loss 2.1525 Acc 71.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 251/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=60.9, loss=2.02]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 251/350 | Train Loss 1.8347 Acc 55.20% | Val Loss 2.1930 Acc 69.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 252/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=52.4, loss=2.01]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 252/350 | Train Loss 1.8254 Acc 47.51% | Val Loss 2.1502 Acc 71.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 253/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=56.8, loss=2.07]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 253/350 | Train Loss 1.8759 Acc 51.54% | Val Loss 2.1416 Acc 71.70%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 254/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.16it/s, acc=60, loss=1.99]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 254/350 | Train Loss 1.8027 Acc 54.41% | Val Loss 2.1674 Acc 70.70%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 255/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=55.1, loss=1.91]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 255/350 | Train Loss 1.7361 Acc 49.99% | Val Loss 2.1558 Acc 71.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 256/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=50.7, loss=2.04]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 256/350 | Train Loss 1.8511 Acc 46.01% | Val Loss 2.1888 Acc 70.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 257/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=48.7, loss=2.03]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 257/350 | Train Loss 1.8458 Acc 44.15% | Val Loss 2.1720 Acc 69.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 258/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=52.5, loss=2.02]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 258/350 | Train Loss 1.8333 Acc 47.65% | Val Loss 2.1653 Acc 70.70%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 259/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:53<00:00,  2.09it/s, acc=48.6, loss=2]   \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 259/350 | Train Loss 1.8143 Acc 44.10% | Val Loss 2.1442 Acc 71.25%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 260/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=61.9, loss=1.88]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 260/350 | Train Loss 1.7091 Acc 56.16% | Val Loss 2.1453 Acc 72.03%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 261/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=57.7, loss=2.15]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 261/350 | Train Loss 1.9471 Acc 52.35% | Val Loss 2.1247 Acc 71.03%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 262/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=58, loss=1.97]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 262/350 | Train Loss 1.7851 Acc 52.63% | Val Loss 2.1212 Acc 71.14%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 263/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=57.5, loss=2]   \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 263/350 | Train Loss 1.8105 Acc 52.13% | Val Loss 2.1387 Acc 71.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 264/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=56, loss=1.97]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 264/350 | Train Loss 1.7849 Acc 50.77% | Val Loss 2.1437 Acc 71.14%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 265/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=48.3, loss=2.1] \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 265/350 | Train Loss 1.9071 Acc 43.79% | Val Loss 2.1639 Acc 70.81%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 266/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=61.2, loss=1.88]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 266/350 | Train Loss 1.7085 Acc 55.54% | Val Loss 2.1645 Acc 69.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 267/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=58, loss=2]     \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 267/350 | Train Loss 1.8180 Acc 52.61% | Val Loss 2.1922 Acc 70.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 268/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.16it/s, acc=57.2, loss=2.05]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 268/350 | Train Loss 1.8597 Acc 51.85% | Val Loss 2.1644 Acc 70.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 269/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=56.2, loss=2.03]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 269/350 | Train Loss 1.8456 Acc 51.00% | Val Loss 2.1669 Acc 71.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 270/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=59.8, loss=2.03]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 270/350 | Train Loss 1.8377 Acc 54.24% | Val Loss 2.1370 Acc 71.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 271/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:53<00:00,  2.09it/s, acc=52, loss=1.97]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 271/350 | Train Loss 1.7889 Acc 47.20% | Val Loss 2.1711 Acc 71.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 272/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=55.3, loss=2.04]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 272/350 | Train Loss 1.8491 Acc 50.13% | Val Loss 2.1583 Acc 71.25%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 273/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=55.6, loss=2.07]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 273/350 | Train Loss 1.8756 Acc 50.44% | Val Loss 2.1776 Acc 70.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 274/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=57.7, loss=2.12]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 274/350 | Train Loss 1.9261 Acc 52.32% | Val Loss 2.1484 Acc 69.92%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 275/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=58.8, loss=2.15]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 275/350 | Train Loss 1.9469 Acc 53.37% | Val Loss 2.1746 Acc 69.70%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 276/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=57.6, loss=1.97]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 276/350 | Train Loss 1.7828 Acc 52.24% | Val Loss 2.1375 Acc 70.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 277/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=53.9, loss=2.11]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 277/350 | Train Loss 1.9106 Acc 48.86% | Val Loss 2.1222 Acc 71.14%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 278/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:53<00:00,  2.09it/s, acc=51.6, loss=2]   \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 278/350 | Train Loss 1.8167 Acc 46.80% | Val Loss 2.1442 Acc 70.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 279/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=56.4, loss=2.11]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 279/350 | Train Loss 1.9145 Acc 51.17% | Val Loss 2.1213 Acc 71.92%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 280/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=56.7, loss=2.12]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 280/350 | Train Loss 1.9223 Acc 51.45% | Val Loss 2.1722 Acc 71.14%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 281/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=52, loss=2.08]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 281/350 | Train Loss 1.8882 Acc 47.20% | Val Loss 2.1265 Acc 71.92%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 282/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=53.2, loss=2.04]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 282/350 | Train Loss 1.8483 Acc 48.30% | Val Loss 2.1310 Acc 72.59%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 283/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=47.5, loss=2.02]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 283/350 | Train Loss 1.8330 Acc 43.08% | Val Loss 2.1240 Acc 71.81%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 284/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=58.5, loss=2.01]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 284/350 | Train Loss 1.8211 Acc 53.03% | Val Loss 2.1882 Acc 71.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 285/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=57.3, loss=2.15]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 285/350 | Train Loss 1.9459 Acc 51.99% | Val Loss 2.1672 Acc 71.25%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 286/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=58.8, loss=1.91]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 286/350 | Train Loss 1.7286 Acc 53.34% | Val Loss 2.1783 Acc 71.25%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 287/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=56.4, loss=1.93]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 287/350 | Train Loss 1.7521 Acc 51.11% | Val Loss 2.2032 Acc 70.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 288/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=56.8, loss=1.97]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 288/350 | Train Loss 1.7910 Acc 51.48% | Val Loss 2.1391 Acc 71.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 289/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.16it/s, acc=50.3, loss=2.02]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 289/350 | Train Loss 1.8279 Acc 45.59% | Val Loss 2.1497 Acc 71.81%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 290/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=54.9, loss=2.06]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 290/350 | Train Loss 1.8691 Acc 49.76% | Val Loss 2.2118 Acc 71.03%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 291/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.11it/s, acc=58.3, loss=1.87]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 291/350 | Train Loss 1.6959 Acc 52.92% | Val Loss 2.1377 Acc 71.25%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 292/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.17it/s, acc=60, loss=1.95]  \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 292/350 | Train Loss 1.7660 Acc 54.44% | Val Loss 2.1672 Acc 71.03%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 293/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.18it/s, acc=56.7, loss=1.88]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 293/350 | Train Loss 1.7077 Acc 51.45% | Val Loss 2.1507 Acc 70.70%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 294/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.14it/s, acc=59.4, loss=2.15]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 294/350 | Train Loss 1.9484 Acc 53.90% | Val Loss 2.1318 Acc 71.92%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 295/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:51<00:00,  2.15it/s, acc=53, loss=2]     \nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 295/350 | Train Loss 1.8101 Acc 48.04% | Val Loss 2.1401 Acc 71.81%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 296/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.13it/s, acc=63.4, loss=2.07]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 296/350 | Train Loss 1.8745 Acc 57.51% | Val Loss 2.1642 Acc 70.03%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 297/350 Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:52<00:00,  2.12it/s, acc=53.4, loss=1.91]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:12<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 297/350 | Train Loss 1.7310 Acc 48.41% | Val Loss 2.1407 Acc 71.14%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 298/350 Train:   7%|â–‹         | 8/111 [00:04<00:35,  2.86it/s, acc=19.1, loss=1.42]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}